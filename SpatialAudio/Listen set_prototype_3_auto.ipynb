{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c342d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import sys, glob\n",
    "import soundfile as sf # read audio\n",
    "import sounddevice as sd\n",
    "import random\n",
    "import threading\n",
    "import librosa # resample function\n",
    "from scipy import signal # fst convolution function\n",
    "from IPython.display import Audio # Audio listening in notebook\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f2f7abf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Bae JaeHyeong'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재위치 확인\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b84fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위치 이동\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd17c2c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T000_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T015_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T030_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T045_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T060_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T075_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T090_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T105_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T120_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T135_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T150_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T165_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T180_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T195_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T210_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T225_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T240_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T255_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T270_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T285_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T300_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T315_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T330_P000.wav',\n",
       " 'Desktop/HRTFsets/IRC_1021_C\\\\IRC_1021_C_R0195_T345_P000.wav']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sound source와 hrtf 불러오기\n",
    "source_dir = '.jupyter/Sound Sample/*.wav'\n",
    "hrtf_dir_LISTEN = 'Desktop/HRTFsets/IRC_1021_C/*.wav'\n",
    "\n",
    "_SOURCES = glob.glob(source_dir)\n",
    "_LISTEN = glob.glob(hrtf_dir_LISTEN)\n",
    "_LISTEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfe7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stereo audio -> mono audio, 실행시킬 필요 없음\n",
    "def convert_mono(idx):\n",
    "    [sig, fs_s] = sf.read(_SOURCES[idx])\n",
    "    if sig.shape[1]>1:\n",
    "        sig_mono = np.mean(sig,axis=1)\n",
    "    else:\n",
    "        sig_mono = sig\n",
    "    sf.write(\"_mono.wav\", sig_mono, fs_s)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf8e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stereo audio -> mono audio, 실행시킬 필요 없음\n",
    "convert_mono(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d27454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환기 및 합성기\n",
    "def convolve_HRTF(time = 1, max_dis = 10, half_cam_angle = 43.5, xpixel = 950):\n",
    "    \n",
    "    totarr = []\n",
    "    min_dis = max_dis\n",
    "    \n",
    "    # arr[0] = type, arr[1] = d, arr[2] = x, arr[3] = y\n",
    "    arr = list(map(float, input(\"Please input [type, depth, x, y]\\n\").split()))\n",
    "    while arr[0]:\n",
    "        newarr = [int(arr[0])]\n",
    "        newarr.append(math.sqrt((2*max_dis*math.tan(half_cam_angle/180)/xpixel*abs(arr[2]-xpixel/2))**2+arr[1]**2))\n",
    "        newarr.append(-math.degrees(np.arctan(2*max_dis*math.tan(half_cam_angle/180)/xpixel*(arr[2]-xpixel/2)/arr[1])))\n",
    "        if(arr[2] > xpixel/2):\n",
    "            newarr[2] = 360 + newarr[2]\n",
    "        if(newarr[1] < min_dis):\n",
    "            min_dis = newarr[1]\n",
    "        print(newarr)\n",
    "        totarr.append(newarr)\n",
    "        arr = list(map(float, input().split()))\n",
    "\n",
    "    L = 0\n",
    "    R = 0\n",
    "\n",
    "    # type = arr[0], distance = arr[1], degree = arr[2]\n",
    "    for arr in totarr:\n",
    "        idx = round(arr[2]/15) % 24\n",
    "        print(_LISTEN[idx])\n",
    "\n",
    "        # Load HRTF sets\n",
    "        HRIR, fs_H = librosa.load(_LISTEN[idx], sr=48000, mono=False)\n",
    "\n",
    "        # Load source to spatialize\n",
    "        [src, fs_s] = librosa.load(_SOURCES[arr[0]-1], mono=True, sr=48000)\n",
    "\n",
    "        # Convolve -> Frequency domain is faster\n",
    "        s_L = signal.fftconvolve(src,HRIR[0,:]) # spatialized source L\n",
    "        s_R = signal.fftconvolve(src,HRIR[1,:]) # spatialized source R\n",
    "\n",
    "        if(len(s_L) != 48883):\n",
    "            s_L = np.pad(s_L,(0,(48883-len(s_L))),'constant')\n",
    "            s_R = np.pad(s_R,(0,(48883-len(s_R))),'constant')\n",
    "        \n",
    "        # Add L signals and R signals, create stereo file\n",
    "        L += s_L * (max_dis - arr[1]) / max_dis\n",
    "        R += s_R * (max_dis - arr[1]) / max_dis\n",
    "\n",
    "    HRTF_Mix = np.vstack([L,R]).transpose()\n",
    "\n",
    "    # Scale the amplitude to peak at 1 (normalize)\n",
    "    HRTF_Mix = HRTF_Mix/np.max(np.abs(HRTF_Mix)) * (max_dis - min_dis) / max_dis\n",
    "    sf.write(f'{time}.wav',HRTF_Mix,48000)\n",
    "\n",
    "    # Audio\n",
    "    sd.play(HRTF_Mix, 48000, device=None)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf0a6997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환기 및 합성기(자동화)\n",
    "def convolve_HRTF_auto(time = 1, max_dis = 10, half_cam_angle = 43.5, xpixel = 950):\n",
    "    \n",
    "    totarr, infoarr = [], []\n",
    "    min_dis = max_dis\n",
    "    \n",
    "    # arr[0] = type, arr[1] = d, arr[2] = x, arr[3] = y\n",
    "    \n",
    "    f = open(\"Desktop/info.txt\", 'r')\n",
    "    while 1:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        infoarr.append(list(map(int, line.split())))\n",
    "    for arr in infoarr:\n",
    "        newarr = [arr[0]]\n",
    "        newarr.append(math.sqrt((2*max_dis*math.tan(half_cam_angle/180)/xpixel*abs(arr[2]-xpixel/2))**2+arr[1]**2))\n",
    "        newarr.append(-math.degrees(np.arctan(2*max_dis*math.tan(half_cam_angle/180)/xpixel*(arr[2]-xpixel/2)/arr[1])))\n",
    "        if(arr[2] > xpixel/2):\n",
    "            newarr[2] = 360 + newarr[2]\n",
    "        if(newarr[1] < min_dis):\n",
    "            min_dis = newarr[1]\n",
    "        print(newarr)\n",
    "        totarr.append(newarr)\n",
    "\n",
    "    L = 0\n",
    "    R = 0\n",
    "\n",
    "    # type = arr[0], distance = arr[1], degree = arr[2]\n",
    "    for arr in totarr:\n",
    "        idx = round(arr[2]/15) % 24\n",
    "        print(_LISTEN[idx])\n",
    "\n",
    "        # Load HRTF sets\n",
    "        HRIR, fs_H = librosa.load(_LISTEN[idx], sr=48000, mono=False)\n",
    "\n",
    "        # Load source to spatialize\n",
    "        [src, fs_s] = librosa.load(_SOURCES[arr[0]-1], mono=True, sr=48000)\n",
    "\n",
    "        # Convolve -> Frequency domain is faster\n",
    "        s_L = signal.fftconvolve(src,HRIR[0,:]) # spatialized source L\n",
    "        s_R = signal.fftconvolve(src,HRIR[1,:]) # spatialized source R\n",
    "\n",
    "        if(len(s_L) != 48883):\n",
    "            s_L = np.pad(s_L,(0,(48883-len(s_L))),'constant')\n",
    "            s_R = np.pad(s_R,(0,(48883-len(s_R))),'constant')\n",
    "        \n",
    "        # Add L signals and R signals, create stereo file\n",
    "        L += s_L * (max_dis - arr[1]) / max_dis\n",
    "        R += s_R * (max_dis - arr[1]) / max_dis\n",
    "\n",
    "    HRTF_Mix = np.vstack([L,R]).transpose()\n",
    "\n",
    "    # Scale the amplitude to peak at 1 (normalize)\n",
    "    HRTF_Mix = HRTF_Mix/np.max(np.abs(HRTF_Mix)) * (max_dis - min_dis) / max_dis\n",
    "    sf.write(f'{time}.wav',HRTF_Mix,48000)\n",
    "\n",
    "    # Audio\n",
    "    sd.play(HRTF_Mix, 48000, device=None)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c607cb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolve_HRTF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba092066",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1.1388026588676001, 331.4158382220707]\n",
      "[2, 2.4569011854794915, 35.50808646951002]\n",
      "Desktop/HRTFsets/IRC_1021_C\\IRC_1021_C_R0195_T330_P000.wav\n",
      "Desktop/HRTFsets/IRC_1021_C\\IRC_1021_C_R0195_T030_P000.wav\n"
     ]
    }
   ],
   "source": [
    "convolve_HRTF_auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22edd5af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'min_dis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[43mtest_HRTF_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m totarr \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m30\u001b[39m],[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m345\u001b[39m]]\n\u001b[0;32m     40\u001b[0m test_HRTF_1()\n",
      "Cell \u001b[1;32mIn[5], line 33\u001b[0m, in \u001b[0;36mtest_HRTF_1\u001b[1;34m(max_dis)\u001b[0m\n\u001b[0;32m     30\u001b[0m HRTF_Mix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([L,R])\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Scale the amplitude to peak at 1 (normalize)\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m HRTF_Mix \u001b[38;5;241m=\u001b[39m HRTF_Mix\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax(np\u001b[38;5;241m.\u001b[39mabs(HRTF_Mix)) \u001b[38;5;241m*\u001b[39m (max_dis \u001b[38;5;241m-\u001b[39m \u001b[43mmin_dis\u001b[49m) \u001b[38;5;241m/\u001b[39m max_dis\n\u001b[0;32m     34\u001b[0m sd\u001b[38;5;241m.\u001b[39mplay(HRTF_Mix, \u001b[38;5;241m48000\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'min_dis' is not defined"
     ]
    }
   ],
   "source": [
    "totarr = [[1,3,30]]\n",
    "\n",
    "def test_HRTF_1(max_dis = 10):\n",
    "    # arr[0] = type, arr[1] = d, arr[2] = x, arr[3] = y\n",
    "    L = 0\n",
    "    R = 0\n",
    "\n",
    "    # type = arr[0], distance = arr[1], degree = arr[2]\n",
    "    for arr in totarr:\n",
    "        idx = round(arr[2]/15)\n",
    "\n",
    "        # Load HRTF sets\n",
    "        HRIR, fs_H = librosa.load(_LISTEN[idx], sr=48000, mono=False)\n",
    "\n",
    "        # Load source to spatialize\n",
    "        [src, fs_s] = librosa.load(_SOURCES[arr[0]-1], mono=True, sr=48000)\n",
    "\n",
    "        # Convolve -> Frequency domain is faster\n",
    "        s_L = signal.fftconvolve(src,HRIR[0,:]) # spatialized source L\n",
    "        s_R = signal.fftconvolve(src,HRIR[1,:]) # spatialized source R\n",
    "\n",
    "        if(len(s_L) != 48883):\n",
    "            s_L = np.pad(s_L,(0,(48883-len(s_L))),'constant')\n",
    "            s_R = np.pad(s_R,(0,(48883-len(s_R))),'constant')\n",
    "        \n",
    "        # Add L signals and R signals, create stereo file\n",
    "        L += s_L * (max_dis - arr[1] / max_dis)\n",
    "        R += s_R * (max_dis - arr[1] / max_dis)\n",
    "\n",
    "    HRTF_Mix = np.vstack([L,R]).transpose()\n",
    "\n",
    "    # Scale the amplitude to peak at 1 (normalize)\n",
    "    HRTF_Mix = HRTF_Mix/np.max(np.abs(HRTF_Mix)) * (max_dis - min_dis) / max_dis\n",
    "    sd.play(HRTF_Mix, 48000, device=None)\n",
    "    input('')\n",
    "    return\n",
    "\n",
    "test_HRTF_1()\n",
    "totarr = [[1,3,30],[1,1,345]]\n",
    "test_HRTF_1()\n",
    "test_HRTF_1()\n",
    "test_HRTF_1()\n",
    "test_HRTF_1()\n",
    "totarr = [[2,5,315],[3,1,345]]\n",
    "test_HRTF_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d73a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_HRTF(max_dis = 10):\n",
    "    angle_list = [0, 15, 30, 45, 315, 330, 345]\n",
    "    totarr = []\n",
    "    \n",
    "    list_sound = [1, 2, 3]\n",
    "    type_list = [random.choice(list_sound) for i in range(random.choice(list_sound))]\n",
    "    type_list.sort()\n",
    "    for typ in type_list:\n",
    "        totarr.append(list([typ]))\n",
    "    \n",
    "    L, R, min_dis = 0, 0, 10\n",
    "\n",
    "    # type = arr[0], distance = arr[1], degree = arr[2]\n",
    "    for i in range(len(type_list)):\n",
    "        dis = random.randrange(11)\n",
    "        totarr[i].append(dis)\n",
    "        if dis < min_dis:\n",
    "            min_dis = dis\n",
    "        totarr[i].append(random.choice(angle_list))\n",
    "        idx = totarr[i][2]//15\n",
    "\n",
    "        # Load HRTF sets\n",
    "        HRIR, fs_H = librosa.load(_LISTEN[idx], sr=48000, mono=False)\n",
    "\n",
    "        # Load source to spatialize\n",
    "        [src, fs_s] = librosa.load(_SOURCES[totarr[i][0]-1], mono=True, sr=48000)\n",
    "\n",
    "        # Convolve -> Frequency domain is faster\n",
    "        s_L = signal.fftconvolve(src,HRIR[0,:]) # spatialized source L\n",
    "        s_R = signal.fftconvolve(src,HRIR[1,:]) # spatialized source R\n",
    "\n",
    "        if(len(s_L) != 48883):\n",
    "            s_L = np.pad(s_L,(0,(48883-len(s_L))),'constant')\n",
    "            s_R = np.pad(s_R,(0,(48883-len(s_R))),'constant')\n",
    "        \n",
    "        # Add L signals and R signals, create stereo file\n",
    "        L += s_L * (max_dis - totarr[i][1] / max_dis)\n",
    "        R += s_R * (max_dis - totarr[i][1] / max_dis)\n",
    "\n",
    "    HRTF_Mix = np.vstack([L,R]).transpose()\n",
    "    \n",
    "    # Scale the amplitude to peak at 1 (normalize)\n",
    "    HRTF_Mix = HRTF_Mix/np.max(np.abs(HRTF_Mix)) * (max_dis - min_dis) / max_dis\n",
    "    \n",
    "    def play_sound(sound):\n",
    "        sd.play(sound, 48000, device=None)\n",
    "\n",
    "    play_sound(HRTF_Mix)\n",
    "    num = int(input(\"Predict the number of obstacle. If you want to play sound one more time, input 0\\n\"))\n",
    "    while(num == 0):\n",
    "        play_sound(HRTF_Mix)\n",
    "        num = int(input(\"Predict the number of obstacle. If you want to play sound one more time, input 0\\n\"))\n",
    "    while(num != len(type_list)):\n",
    "        num = int(input(\"Wrong answer, Please listen careful and predict the number of obstacles\"))\n",
    "        play_sound(HRTF_Mix)\n",
    "    print(\"Right Answer\")\n",
    "    for i in range(num):\n",
    "        toggle = 0\n",
    "        arr = input(f'Predict the [type, dis, angle] of obstacle{i+1}.\\ntype: 1-car, 2-people, 3-wall / dis: 0~10 / angle: 0~45, 315~345\\n')\n",
    "        for j in range(len(type_list)):\n",
    "            if(totarr[j] == arr):\n",
    "                toggle = 1\n",
    "                totarr.pop(j)\n",
    "                break\n",
    "        if(toggle):\n",
    "            print(\"Correct!\")\n",
    "        else:\n",
    "            print(\"Wrong\")\n",
    "    print(totarr)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17c416",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_HRTF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a814e1d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
